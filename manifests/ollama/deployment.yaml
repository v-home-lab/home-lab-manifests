apiVersion: v1
kind: Namespace
metadata:
  name: ollama-llama
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-llama
  labels:
    app: ollama-llama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama-llama
  template:
    metadata:
      labels:
        app: ollama-llama
    spec:
      containers:
        - name: ollama-llama
          image: alpine/llama3.2:latest
          ports:
            - containerPort: 11434
          resources:
            limits:
              memory: "8Gi"
              cpu: "4"
            requests:
              memory: "4Gi"
              cpu: "2"
          readinessProbe:
            httpGet:
              path: /api/version
              port: 11434
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /api/version
              port: 11434
            initialDelaySeconds: 10
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: ollama-llama-service
  labels:
    app: ollama-llama
spec:
  selector:
    app: ollama-llama
  ports:
    - protocol: TCP
      port: 80
      targetPort: 11434
  type: LoadBalancer

---

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama-llama
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/v-home-lab/home-lab-manifests.git
    targetRevision: master
    path: manifests/ollama
  destination:
    server: "https://kubernetes.default.svc"
    namespace: ollama-llama
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    retry:
      limit: 5
      backoff:
        duration: 30s
        factor: 2
        maxDuration: 5m
